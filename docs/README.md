# EcoVision: 
## Sistema de inteligencia artificial basado en visiÃ³n por computadora para la detecciÃ³n y segmentaciÃ³n de latas y botellas

[![Python Version](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/pytorch%2B-orange.svg)](https://pytorch.org)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache2.0-yellow.svg)](https://www.apache.org/licenses/LICENSE-2.0)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://docker.com)


##  Autores
**Jose Luis Martinez Diaz** Codigo-UAO: ***2247574***

**Juan David Arroyave Ramirez** Codigo-UAO: ***2250424***

**Neiberth Aponte Aristizabal** Codigo-UAO: ***2251022*** 

**Stevens Ricardo Bohorquez Ruiz** Codigo-UAO: ***2250760***

##  DescripciÃ³n del Proyecto
La gestiÃ³n de residuos sÃ³lidos representa un desafÃ­o crÃ­tico en Colombia, donde la acumulaciÃ³n de latas y botellas plÃ¡sticas contamina ecosistemas acuÃ¡ticos y terrestres y eleva costos operativos de recolecciÃ³n. Este trabajo propone un sistema de inteligencia artificial basado en visiÃ³n por computadora y Deep Learning para la detecciÃ³n y segmentaciÃ³n de latas y botellas, entrenado con YOLOv8 y desplegado
mediante una interfaz Streamlit. Los objetivos incluyen la recolecciÃ³n y anotaciÃ³n de un dataset diverso en Roboflow, el entrenamiento y optimizaciÃ³n del modelo con tÃ©cnicas de Data Augmentation y ajuste de hiperparÃ¡metros, la validaciÃ³n en entornos controlados usando mÃ©tricas de precisiÃ³n y graficas de perdida. El alcance comprende el desarrollo del modelo, la aplicaciÃ³n web, la documentaciÃ³n tÃ©cnica y
pruebas de campo con videos de Playas, orillas de rÃ­os, zonas urbanas, o CCTV libres de derechos de autor que estÃ©n disponibles para uso acadÃ©mico sin fines comerciales o en datasets pÃºblicos o los generados por
EcoVision, excluyendo la recolecciÃ³n manual de datos en tiempo real, la provisiÃ³n de infraestructura de hardware, mantenimiento o soporte continuo post-entrega y desarrollo de modelos adicionales distintos a
YOLOv8. Este enfoque aporta datos objetivos para optimizar rutas de recolecciÃ³n, apoyar iniciativas de economÃ­a circular y facilitar la toma de decisiones en autoridades ambientales y redes de recicladores

### Objetivos del Proyecto

**Objetivo General**: Desarrollar un sistema de inteligencia artificial basado en visiÃ³n por computadora para la detecciÃ³n y segmentaciÃ³n de latas y botellas, con el fin de apoyar la identificaciÃ³n automatizada
de contaminantes y fortalecer estrategias de gestiÃ³n ambiental.

 **Objetivo EspecÃ­fico**: Entrenar y evaluar un modelo de visiÃ³n por computadora para la detecciÃ³n y segmentaciÃ³n de objetos utilizando YOLOv8.

 **Objetivo TÃ©cnico**: Desplegar el sistema de inteligencia artificial basado en visiÃ³n por computadora mediante la plataforma Streamlit, desarrollando una interfaz web interactiva que permita la carga de imÃ¡genes, videos, activaciÃ³n de la cÃ¡mara para la utilizaciÃ³n del modelo en tiempo real.


### MetodologÃ­a

- **Modelo**: YOLOv8 para detecciÃ³n de objetos en tiempo real que utiliza una arquitectura de redes neuronales convolucionales (CNN).
- **Entrada**: ImÃ¡genes o videos de latas y botellas.
- **Preprocesamiento**: Entrenamiento de imagenes relacionadas, proceso de normalizaciÃ³n, y fine-tuning.
- **VisualizaciÃ³n**: Camara en tiempo real o inserciÃ³n manual de imagenes o videos relacionados para explicabilidad del modelo
- **Interfaz**: Graphic User Interface (GUI) desarrollada en Streamlit para facilidad de uso.

---

## Estructura del Proyecto

```
ECOVISION/
â”‚
â”œâ”€â”€ ğŸ“ venv/
â”œâ”€â”€ ğŸ“ data/
|   â””â”€â”€ ğŸ“ external 
|   â””â”€â”€ ğŸ“ processed
|   â””â”€â”€ ğŸ“‚ raw                                      
â”œâ”€â”€ ğŸ“ docs/
|   â””â”€â”€ ğŸ“– README.md
â”œâ”€â”€ ğŸ“ notebooks/
â”œâ”€â”€ ğŸ“ reports/                                        
â”œâ”€â”€ ğŸ“ src/                                           # CÃ³digo fuente principal
|   â””â”€â”€ ğŸ“ data 
|         â”œâ”€â”€ â–¶PENDIENTE.py                           # codigo original, alto acople y sin cohesion
|         â”œâ”€â”€ â–¶PENDIENTE.py                           #
|         â”œâ”€â”€ â–¶integrator.py                          # MÃ³dulo integrador del pipeline
|         â”œâ”€â”€ â–¶load_model.py                          # Carga del modelo Ecovision-YOLOv8
|         â”œâ”€â”€ â–¶preprocess_img.py                      # Preprocesamiento de imÃ¡genes
|         â”œâ”€â”€ â–¶read_img.py                            # Lectura de imÃ¡genes JPG/PNG
|   â””â”€â”€ ğŸ“ features
|   â””â”€â”€ ğŸ“‚ models                                     # Modelo .H5 .PKL                   
|   â””â”€â”€ ğŸ“‚ visualizations/
â”‚         â”œâ”€â”€ PENDIENTE.png                           # Visualizacion del modelo desde Netron.app
â”‚         â”œâ”€â”€ PENDIENTE.png                           # Visualizacion del diagrama flujo de datos
â”‚         â”œâ”€â”€ PENDIENTE.png                           # Visualizacion de la app funcionando
â”‚         â”œâ”€â”€ Model_Summary.png                       # Visualizacion del modelo desde tf.keras
â”œâ”€â”€ ğŸ“ tests/
â”‚         â”œâ”€â”€ ğŸ“‚JPG/
â”‚               â”œâ”€â”€ Imagenes para testeo .jpg 
â”‚         â”œâ”€â”€ Archivos .py utilizados para las pruebas unitarias
â”œâ”€â”€ ğŸš« .gitignore                                     # Archivos ignorados por Git
â”œâ”€â”€ ğŸ”¢ .python-version                                # VersiÃ³n de Python especificada
â”œâ”€â”€ ğŸ³ Dockerfile                                     # ConfiguraciÃ³n para la imagen contenedora
â”œâ”€â”€ âš–ï¸ LICENSE                                        # Licencia Apache 2.0
â”œâ”€â”€ ğŸ¤– main.py                                        # Archivo principal Streamlit
â”œâ”€â”€ ğŸ“‹ pyproject.toml                                 # ConfiguraciÃ³n del proyecto UV
â”œâ”€â”€ ğŸ“„ requirements.txt                               # Dependencias del proyecto
â”œâ”€â”€ ğŸ”’ uv.lock                                        # Lock file de dependencias UV
â”œâ”€â”€ ğŸš€ Makefile

```

---

## Requisitos

### VersiÃ³n de Python
- **Python**: 3.11 para mejor compatibilidad con TorchVision y YOLOv8

### ğŸ’» Requisitos del Sistema
- **RAM**: MÃ­nimo 4GB (recomendado 8GB o superior)
- **Espacio en disco**: 5GB libres como minimo

---

## InstalaciÃ³n del Repositorio

### MÃ©todo 1: InstalaciÃ³n con UV (Recomendado)

#### 1. Clonar el repositorio
```bash
git clone https://github.com/davidarroyave/EcoVision
cd UAO-Neumonia
```

#### 2. Instalar UV (si no lo tienes)
```bash
# Linux/macOS
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

#### 3. Crear entorno e instalar dependencias
```bash
# Crear entorno virtual automÃ¡ticamente e instalar dependencias
uv sync

# Activar entorno virtual
source .venv/bin/activate  # Linux/macOS
# o
.venv\Scripts\activate     # Windows
.venv\bin\activate         # Windows

```
#### 4. Descargar el modelo (si no estÃ¡ incluido)
```bash
# El modelo .PT debe estar en la carpeta models/
# Si no estÃ¡ presente, contactar al equipo de desarrollo
```

#### 5. Ejecutar la aplicaciÃ³n
```bash
make streamlit #OpciÃ³n 1 (Recomendada)
streamlit run main.py #OpciÃ³n 2
#Si no se abre automaticamente, ingresar al link que arroja la consola: http://localhost:8501
```
### MÃ©todo 2: InstalaciÃ³n con Docker [![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](docker/README.md)


## MÃ©todo 3: InstalaciÃ³n Manual con pip

#### 1. Clonar y preparar entorno
```bash
git clone https://github.com/davidarroyave/ecovision
cd ecovision

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/macOS
# o
venv\Scripts\activate     # Windows
.venv\bin\activate        # Windows  
```

#### 2. Instalar dependencias
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

#### 3. Verificar instalaciÃ³n
```bash
python -c "import torch; print(f'Torch: {torch.__version__}')"
```

### VerificaciÃ³n de InstalaciÃ³n

```bash
# Ejecutar tests bÃ¡sicos
python -m pytest tests/ -v

# Verificar modelo
python -c "
from src.load_model import model_fun
model = model_fun()
print('Modelo cargado correctamente' if model else 'Error al cargar modelo')
"

# Probar interfaz (modo headless para servidores)
python main.py --test
```
## ğŸ”¬ Tipos de residuos de latas y botellas Detectados

El modelo **YOLOv8** estÃ¡ entrenado para clasificar las siguientes condiciones:

| Clase | CÃ³digo | DescripciÃ³n | PrecisiÃ³n |
|-------|--------|-------------|-----------|
| **ğŸ¥« Lata** | `###` | Latas detectadas por el modelo | %%%% |
| **ğŸ¾ Botella** | `###` | Botellas detectadas por el modelo | %%%% |

**PrecisiÃ³n general del modelo**:%%%%

---

## DescripciÃ³n Detallada de MÃ³dulos

### `main.py` - Interfaz Streamlit Principal
**FunciÃ³n**: Punto de entrada de la aplicaciÃ³n con interfaz Streamlit.

**CaracterÃ­sticas**:


**Widgets principales**:


### `src/data/integrator.py` - MÃ³dulo Integrador Principal
**FunciÃ³n**: Orquesta todo el pipeline de predicciÃ³n.

**Flujo de trabajo**:


**Funciones clave**:


### `src/data/camera.py` - ActivaciÃ³n de la cÃ¡mara en tiempo real
**FunciÃ³n**: Activa la cÃ¡mara en tiempo real desde streamlit en tu dispositivo, ya sea computador o celular.

**Capacidades**:


**Funciones**:



### ğŸ¤– `src/data/load_model.py` - Carga del Modelo
**FunciÃ³n**: GestiÃ³n y carga del modelo de red neuronal.

**CaracterÃ­sticas**:
- ğŸ“‚ Carga de `models/.pt`
- âœ… VerificaciÃ³n de existencia de archivo
- ğŸ›¡ï¸ Manejo de errores de compatibilidad
- ğŸ” ValidaciÃ³n de arquitectura (YOLOv8)

---

## ğŸš€ Ejecuciones
- ğŸ–¥ Abrir MLflow UI: Terminal en `C:\EcoVision`, activar `.\venv\Scripts\activate`, ejecutar `make mlflow`, abrir [http://localhost:5000](http://localhost:5000).  
- ğŸ§ª Test carga del modelo: `make test-modelo` â†’ verifica rutas inexistentes y carga simulada con mocks.  
- ğŸ§ª Test proceso del modelo: `make test-proceso` â†’ valida `process_frame` sin modelo y con mocks.  
- ğŸ“Œ YOLOv8: versiÃ³n estable y compatible con Python/Roboflow; versiones recientes aÃºn en adopciÃ³n temprana.  
- ğŸ“Š Tracking MLflow: configurar `EPOCHS = 5` en `Makefile`, ejecutar `make train`; resultados en `runs/segment/<run_name>`.  
- ğŸ’¾ DVC: instalar `pip install dvc dvc-azure`, `dvc init`, configurar remote Azure (`dvc remote add/modify`), agregar/subir archivos (`dvc add --to-remote` o `dvc push`), otros comandos: `dvc remote list`, `dvc remote default`, `dvc pull`.


---

### ğŸ—ï¸ Arquitectura del Modelo YOLOv8

```bash

               from  n    params  module                                       arguments                     
  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 
  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                
  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             
  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                
  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             
  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               
  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           
  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              
  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           
  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  
 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                
 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 
 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              
 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 
 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          
Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs

```
---

## âš–ï¸ Licencia

Este proyecto estÃ¡ licenciado bajo la **Licencia Apache 2.0** - ver el archivo [LICENSE](LICENSE) para detalles completos.

# ğŸ“š Referencias y BibliografÃ­a

[1] Banco Mundial, What a Waste
2.0: A Global Snapshot of Solid Waste Management to 2050, Accessed: Sept. 27, 2025, sep. de
2018. direcciÃ³n: https://www.bancomundial.org/es/news/immersive - story / 2018 / 09 /20/what-a-waste-an-updatedlook- into- the- future- ofsolid-waste-management.


[2] J. Planelles, â€œCada aÃ±o se vierten mÃ¡s de 52 millones de toneladas de plÃ¡sticos al medioambiente segÃºn un estudio de Natureâ€, El PaÃ­s, sep. de 2024, Accessed: Sept. 27, 2025. direcciÃ³n:
https://elpais.com/climay-medio-ambiente/2024-09-04 / cada - ano - se - vierten -mas - de - 52 - millones - de -toneladas-de-plasticos-almedioambiente-segun-un-estudiode-nature.html.


[3] Greenpeace Colombia, El problema de los residuos, Accessed: Sept. 27, 2025, 2025. direcciÃ³n:
https://www.greenpeace.org/colombia / el - problema - de -los-residuos/.


[4] â€œContaminaciÃ³n de residuos sÃ³-
lidos y sus efectos en la salud y medio ambienteâ€, Revista INVECOM, vol. 4, n.o 2, dic. de
2024, Accessed: Sept. 27, 2025.direcciÃ³n: http://revistainvecom.14org/index.php/invecom/article/
view/3557.


[5] Condensa, Aluminio vs. PlÃ¡stico: La sostenibilidad en envases, Accessed: Sept. 27, 2025,
abr. de 2024. direcciÃ³n: https:/ / condensa . com / 2024 / 04 /17 / aluminio - vs - plastico -
la-sostenibilidad-en-envases/.


[6] ARPAL, Memoria de Actividades 2024, Accessed: Sept. 27, 2025,
jun. de 2025. direcciÃ³n: https://aluminio.org/arpal-presentasu-memoria-de-actividades-
2024/.


[7] â€œSistema de procesamiento de imÃ¡genes para la detecciÃ³n de residuos sÃ³lidosâ€, AIBI Revista
de InvestigaciÃ³n, vol. 13, n.o 1, abr. de 2025, Accessed: Sept. 27, 2025. direcciÃ³n: https://revistas.
udes.edu.co/aibi/article/
view/4426.


[8] Reciclaje y GestiÃ³n, Tendencias
y tecnologÃ­as en gestiÃ³n de residuos para 2024, Accessed: Sept.
27, 2025, mayo de 2024. direcciÃ³n: https://reciclajeygestion.es/2024/05/27/tendenciasy-tecnologias-en-gestionde-residuos-para-2024-innovacionesy - desarrollos - recientes -
en-el-sector/.


[9] Recycleye, La IA y el reconocimiento de residuos: por quÃ© funciona, Accessed: Sept. 27, 2025,
jun. de 2024. direcciÃ³n: https://recycleye.com/es/la-iay - el - reconocimiento - de -residuos/.


[10] â€œUso de la VisiÃ³n Artificial para
la ClasificaciÃ³n de Residuos OrgÃ¡nicos e InorgÃ¡nicosâ€, Nexos CientÃ­ficos, Accessed: Sept. 27, 2025.
direcciÃ³n: https://nexoscientificos.vidanueva.edu.ec/index.php/ojs / article / download / 61 /
268/501.


[11] RCB Trace, Perspectivas futuras: avances tecnolÃ³gicos en la
gestiÃ³n de residuos, Accessed: Sept.27, 2025, abr. de 2024. direcciÃ³n: https://www.rcbtrace.com/perspectivas- futurasavances - tecnologicos - en -la-gestion-de-residuos/.


[12] Recyclever, Reverse Vending: Beneficios y Futuro Sostenible, Accessed: Sept. 27, 2025, feb. de
2025. direcciÃ³n: https://www.recyclever.com/es/blog/article-10/reverse-vending-beneficiosy-futuro-sostenible-310.


[13] Tiempo, Reverse vending: el fenÃ³meno de las mÃ¡quinas que te
pagan por reciclar, Accessed: Sept.27, 2025, dic. de 2024. direcciÃ³n:https : / / www . tiempo . com /
noticias/actualidad/reversevending - el - fenomeno - de -las-maquinas-que-te-paganpor-reciclar.html.


[14] Ultralytics, SegmentaciÃ³n de instancias con seguimiento de objetos, Accessed: Sept. 27, 2025,
mayo de 2025. direcciÃ³n: https://docs.ultralytics.com/es/15guides/instance-segmentationand-tracking/.


[15] Ultralytics, SegmentaciÃ³n de Instancias, Accessed: Sept. 27, 2025,
mar. de 2025. direcciÃ³n: https://docs.ultralytics.com/es/tasks/segment/.


[16] DetecciÃ³n y CuantificaciÃ³n de ErosiÃ³n Fluvial con VisiÃ³n por Computadora, Accessed: Sept. 27, 2025,
dic. de 2021. arXiv: 2507.11301. direcciÃ³n: https://arxiv.org/html/2507.11301v1.


[17] Ultralytics, Un futuro mÃ¡s verde mediante Vision AI y Ultralytics YOLO, Accessed: Sept. 27,
2025, sep. de 2025. direcciÃ³n: https: //www.ultralytics.com/es/blog/greener-future-throughvision-ai-and-ultralyticsyolo


**Ãšltima ActualizaciÃ³n**: Octubre 8, 2025
**Estado del Proyecto**: ProducciÃ³n en desarrollo ğŸŸ¡  